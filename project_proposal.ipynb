{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185d819d-8e3b-41ad-9d97-ff40132d3098",
   "metadata": {},
   "source": [
    "# Group Project Report\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In school, the way used to measure a student’s knowledge is often through exams. To do well on exams, students often resort to spending as much time as possible to study in preparation for them. Nowadays, however, more and more people are emphasizing that studying more and getting high grades do not equate to gaining more knowledge. Thus, we want to investigate whether study time and exam results have an impact on a person’s knowledge level of that subject.\n",
    "\n",
    "**The question we are trying to answer is: based on the time they spend studying and exam performance, what knowledge level would the user have on a subject?**\n",
    "\n",
    "We are using the [User Knowledge Modeling](https://archive.ics.uci.edu/dataset/257/user+knowledge+modeling) dataset from the UCI Machine Learning Repository, donated by Kahraman, Colak, and Sagiroglu in 2013. There 403 observations which have been already split – 258 in the training dataset, and 145 in the testing set. The set contains no missing values. The dataset contains the following columns, in the order of left to right:\n",
    "\n",
    "- user’s degree of study time for the goal subject materials (STG)\n",
    "- user's the degree of repetition for studying the goal subject materials (SCG)\n",
    "- user’s degree of study time for related subjects (STR)\n",
    "- user's exam performance for related subjects (LPR)\n",
    "- user's exam performance for the goal subject (PEG)\n",
    "- user's knowledge level (UNS)-- classified as very low, low, middle, or high. \n",
    "\n",
    "Aside from UNS which indicates the knowledge level of users, the other columns are all dbl variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30587289-0660-4cd8-bb90-db3d905fee24",
   "metadata": {},
   "source": [
    "### Preliminary Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be831fae-3fd1-4708-a9f1-98738c66796d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse) #loading packages\n",
    "library(repr)\n",
    "library(rvest)\n",
    "library(stringr)\n",
    "library(readxl)\n",
    "library(dplyr)\n",
    "library(yardstick)\n",
    "\n",
    "library(tidymodels)\n",
    "\n",
    "install.packages(\"ISLR\")\n",
    "install.packages(\"GGally\")\n",
    "install.packages(\"kknn\")\n",
    "\n",
    "library(kknn)\n",
    "library(ISLR)\n",
    "library(GGally)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570056c6-69ae-4bbc-a3ce-06cadea40ff4",
   "metadata": {},
   "source": [
    "### Reading and Tidying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29018c73-5e9a-4ed5-8ea2-42d09dd7d858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading data from url into jupyter\n",
    "\n",
    "training_data <- read_csv(\"https://raw.githubusercontent.com/thisisyifulin/group_project-group34-/main/Training_Data_User_Modeling_Dataset_Hamdi%20Tolga%20KAHRAMAN.csv\") |>\n",
    "select(STG, SCG, STR, LPR, PEG, UNS)\n",
    "\n",
    "testing_data <- read_csv(\"https://raw.githubusercontent.com/thisisyifulin/group_project-group34-/main/Test_Data_User_Modeling_Dataset_Hamdi%20Tolga%20KAHRAMAN.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb453de-cb40-4b6f-afeb-ba498905b6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head(training_data)\n",
    "tail(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d9da58-ab88-4999-af39-812c0656d938",
   "metadata": {},
   "source": [
    "> <b> Figure 1: </b>\n",
    ">\n",
    ">The training data loaded from the web and present the first and final rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f316f95b-98e6-4276-bce5-6d29afc5b87f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head(testing_data)\n",
    "tail(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f4abc-0788-4acc-b6bf-d2710d23c2b3",
   "metadata": {},
   "source": [
    "> <b> Figure 2: </b>\n",
    ">\n",
    ">The testing data loaded from the web and present the first and final rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ef3f6-15bc-4afd-b340-128e089736f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data is already tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e550f7-cf4d-48a6-a431-3f6f105aa5ac",
   "metadata": {},
   "source": [
    "### Summarizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403973c-4855-4c8e-b0cf-cc6663345742",
   "metadata": {},
   "source": [
    "Now, the data is already read. Our next step is to count and find the mean of each varibles for different category level of UNS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53416d15-00d1-4fcd-95d9-279e042a3a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#summarize\n",
    "\n",
    "#summarize\n",
    "\n",
    "counts_class <- training_data |>\n",
    "                group_by(UNS) |>\n",
    "                summarize(count_class = n())\n",
    "\n",
    "mean_estimates<-training_data|>\n",
    "group_by(UNS)|>\n",
    "summarize(mean_STG=mean(STG),\n",
    "          mean_TEG=mean(PEG),\n",
    "          mean_SCG=mean(STG),\n",
    "          mean_STR=mean(PEG),\n",
    "            mean_LPR=mean(LPR))|>\n",
    "select(-UNS)\n",
    "\n",
    "summary<-counts_class|>\n",
    "mutate(count=count_class)|>\n",
    "select(-count_class)|>\n",
    "cbind(mean_estimates)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a1103-000d-42d9-90ff-e15c2b0a4243",
   "metadata": {
    "tags": []
   },
   "source": [
    "> <b> Figure 3: </b>\n",
    ">\n",
    "> The mean and count for each varibles (STG, PEG, SCG, STR and LPR) and UNS level.\n",
    "?\n",
    "> STG: user’s degree of study time for the goal subject materials\n",
    ">\n",
    "> PEG: user's exam performance for the goal subject\n",
    ">\n",
    "> SCG: user's the degree of repetition for studying the goal subject materials \n",
    ">\n",
    "> STR: user’s degree of study time for related subjects\n",
    ">\n",
    "> LPR: user's exam performance for related subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b589c9f-fdfe-4224-b4c5-fb4a38387470",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "According to the group_by and summarize function, we can see that for different UNS level, the mean of STG, TEG, SCG, STR and LPR are different. These means all these varibles are helpful to help us in predicting a new observation. But it is not realistic to use all varibles as the predictors, so we still need further operation to choose the decide the most useful variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d93d0-1225-478b-979e-988502e5aa1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#finds the mean of predictors\n",
    "\n",
    "select_training_data <- training_data |>\n",
    "select(STG, STR, LPR, PEG, UNS) # selecting the variables\n",
    "\n",
    "\n",
    "#count the number of cells with na and renamed it into column count_ca\n",
    "data_count_na <- summarize(select_training_data, count_na = sum(is.na(select_training_data)))\n",
    "\n",
    "data_count_na\n",
    "#since there are no n/a, there are no rows with n/a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d209846-6c36-4f0b-96f2-b5910e2a864b",
   "metadata": {
    "tags": []
   },
   "source": [
    "><b> Figure 4: </b>\n",
    ">\n",
    ">The count of rows with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1197d7f1-f058-4087-9f7b-99cad407a01e",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis -- Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c421757-5643-414d-ac23-7a3e015762cd",
   "metadata": {},
   "source": [
    "In order to use knn classification, we need to figure out the relationship between different variables. So we using ggplot and ggpairs to measure the strength the relationship between different predictor variables and determine which two variables have the most strong relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a04dc-ddfa-404a-a5fc-b4f850537971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed (1234)\n",
    "options(repr.plot.width = 8, repr.plot.height = 8)\n",
    "\n",
    "pairplot <- training_data |> \n",
    "     ggpairs(\n",
    "         lower = list(continuous = wrap('points', alpha = 0.4)),\n",
    "         diag = list(continuous = \"barDiag\")\n",
    "     ) +\n",
    "     theme(text = element_text(size = 20)) +\n",
    "ggtitle(\"Distribution of Different Variables and Their Correlations\")\n",
    "\n",
    "pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17276822-16f1-4270-a390-009d008731c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "><b> Figure 5: </b>\n",
    ">\n",
    ">Pairplot comparing the distributions of the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027ca7c5-2268-497c-abf7-dd518f420a77",
   "metadata": {},
   "source": [
    "Though we initially expected PEG and STG to have the highest correlation, since they are both related to goal subjects, the two variables which have the most correlation are LPR and PEG with -0.270. Therefore, we will be building our classification model with LPR and PEG as the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05279f4d-4e8c-4bb3-9bd3-6e509ab1b09b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lpr_peg_plot <- ggplot(training_data, aes(x = LPR, y = PEG)) +\n",
    "geom_point(aes(color = UNS)) +\n",
    "labs(x = \"User's Exam Performance on Related Subjects (LPR)\",\n",
    "     y = \"User's Exam Performance on Goal Subjects (PEG)\",\n",
    "     color = \"User Knowledge Level (UNS)\") +\n",
    "theme(text = element_text(size = 15)) +\n",
    "ggtitle(\"Distribution of PEG against LPR\")\n",
    "lpr_peg_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a53d3-735f-4395-9279-377de1f8e0c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "><b> Figure 6: </b>\n",
    ">\n",
    ">Visualization of the correlation between the two selected variables. We can see that a lower PEG seems to have a correlation with a lower UNS. However, it is not as clear what the correlation between LPR and UNS is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780c304-c785-462f-bb1d-e0883d4d8d7e",
   "metadata": {},
   "source": [
    "With our exploratory data analysis, we predict that users who do well on subject goal exams will tend to have high user knowledge levels. Despite LPR having a higher correlation with PEG, it is unclear what studying more in related subjects indicates for the knowledge level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9babf-f149-4c60-9231-7a535f9c25f5",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d48a15-b57a-475e-873f-e5d4d0c8d51a",
   "metadata": {},
   "source": [
    "### Data Analysis — K-nearest neighbor classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452c4c14-7196-44e4-b16b-eac6031bbf96",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to creat a knn classification model to predict a new observation, we need to is to find out the most \n",
    "accurate k value to use. The first step in choosing the parameter K is to generate five different validation sets.\n",
    "Then, creating a specification model and build a recipe that involve UNS as class, LPR and PEG as predictors.\n",
    "Finally, we create a workflow and use the tune_grid function to fit the model for each value in a range of parameter values. Since the data was already pre-split, we do not need to split it again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015c156-e2f9-4905-bbd3-2a147aecdde6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed (1234)\n",
    "\n",
    "options(repr.plot.height = 5, repr.plot.width = 5)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "            set_engine(\"kknn\") |>\n",
    "            set_mode(\"classification\")\n",
    "\n",
    "mnist_recipe <- recipe(UNS ~ PEG + LPR, data = training_data)\n",
    "\n",
    "mnist_vfold <- vfold_cv(training_data, v = 5, strata = UNS)\n",
    "\n",
    "knn_results <- workflow() |>\n",
    "                 add_recipe(mnist_recipe) |>\n",
    "                 add_model(knn_spec) |>\n",
    "                 tune_grid(resamples = mnist_vfold, grid = tibble(neighbors = c(1,2,3,4,5,6,7,8))) |>\n",
    "                 collect_metrics()\n",
    "\n",
    "accuracies <- knn_results |>\n",
    "                 filter(.metric == 'accuracy')\n",
    "\n",
    "cross_val_plot <- ggplot(accuracies, aes(x = neighbors, y = mean)) +\n",
    "                  geom_point() +\n",
    "                  geom_line() +\n",
    "                  labs(x = 'Neighbors', y = 'Accuracy Estimate') +\n",
    "                  theme(text = element_text(size = 10)) +\n",
    "ggtitle(\"Effect of Change in Neighbors on Mean Accuracy\")\n",
    "\n",
    "cross_val_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2fc30f-b7b5-481d-942d-5f4dfab75d42",
   "metadata": {
    "tags": []
   },
   "source": [
    "><b> Figure 7: </b>\n",
    ">\n",
    ">Graph of Accuracy against Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a83968-b411-465b-b0ca-dbaf55b3a007",
   "metadata": {},
   "source": [
    "We see that we get highest accuracy with 3 and 4 neighbors, but since we have 4 classes, we will choose 3 so there is no tie between the classes. We now put k = 3 directly into the specification instead of using tune() function and create a workflow to combine the new specification and recipe. Finally, we fit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54aeec2-9f32-485f-a93a-20493e446c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "new_training_data<-training_data|>\n",
    "select(UNS, LPR, PEG) |>\n",
    "mutate(LPR=as.numeric(LPR))|>\n",
    "mutate(PEG=as.numeric(PEG)) |>\n",
    "mutate(UNS = as.factor(str_replace(training_data$UNS, \"Very Low\", \"very_low\"))) \n",
    "\n",
    "new_testing_data<-testing_data|>\n",
    "select(UNS, LPR, PEG)|>\n",
    "mutate(LPR=as.numeric(LPR))|>\n",
    "mutate(PEG=as.numeric(PEG)) |>\n",
    "mutate(UNS = as.factor(str_replace(testing_data$UNS, \"Very Low\", \"very_low\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf3a113-850b-4c07-a1de-76180d188da5",
   "metadata": {},
   "source": [
    "Here, we mutated the variables in order to fit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189dfd5-b1a2-434d-b27d-f0af9419b0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed (1234)\n",
    "\n",
    "pred1 <- tibble(LPR= 0.87, PEG=0.55)\n",
    "\n",
    "recipe<-recipe(UNS~PEG+LPR, data=new_training_data)|>\n",
    " step_scale(all_predictors())|>\n",
    "    step_center(all_predictors())\n",
    "\n",
    "knn_spec<- nearest_neighbor(weight_func = \"rectangular\", neighbors = 3) |>\n",
    "       set_engine(\"kknn\") |>\n",
    "       set_mode(\"classification\")\n",
    "\n",
    "\n",
    "fit<- workflow() |>\n",
    "          add_recipe(recipe) |>\n",
    "          add_model(knn_spec) |>\n",
    "          fit(data = new_training_data)\n",
    "\n",
    "predicted1<-predict(fit, pred1)\n",
    "predicted1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032d806-a130-4ec2-b338-b11c30e494ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "><b> Figure 8: </b>\n",
    ">\n",
    ">Predict a new observation's UNS level, checking to see if the program is functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a63147-f851-471f-a14d-fef8a6709b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Now, we check the accuracy of our classification model against the actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02de87-4987-46b5-9a83-ea1eda43e414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed (1234)\n",
    "test_predictions <- predict(fit, new_testing_data) |>\n",
    "  bind_cols(new_testing_data)\n",
    "\n",
    "\n",
    "classification_metrics <- test_predictions |>\n",
    "metrics(truth = UNS, estimate=.pred_class)|>\n",
    "filter(.metric == \"accuracy\")\n",
    "\n",
    "\n",
    "classification_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335464d9-3e98-4365-a932-ae7fabae1bab",
   "metadata": {
    "tags": []
   },
   "source": [
    "><b> Figure 9: </b>\n",
    ">\n",
    ">The accuracy of the k-nearest neighbor classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4744471-eb4f-41eb-bbe5-ddb96f45fb04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed (1234)\n",
    "\n",
    "conf_mat <- test_predictions |> \n",
    "      conf_mat(truth = UNS, estimate = .pred_class)\n",
    "\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7e8729-9b1c-40d9-a7bd-3850f92c9e96",
   "metadata": {
    "tags": []
   },
   "source": [
    "><b> Figure 10: </b>\n",
    ">\n",
    ">The distribution of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80905310-9d11-4633-b443-ca0bf43608bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "We assign the testing data into the classification model and compare the predictions and the actual UNS level of \n",
    "the observations in the testing dataset to get the accuracy of our model. We can combine the predictions with \n",
    "our actual dataset together and use metrics to calculate the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fdf8c8-9743-4bd7-9250-7002ed643a32",
   "metadata": {},
   "source": [
    "We can see the accuracy is around 95%, which makes this a successful model. However, we are still curious what role does the predictor LPR play in this model as it does not show its importance in the scatter plot. We will run the accuracy test again but this time with just predictor PEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b69357c-ce20-486c-a8e5-5cd27d85c3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recipe_PEG<-recipe(UNS~PEG, data=new_training_data)|>\n",
    " step_scale(all_predictors())|>\n",
    "    step_center(all_predictors())\n",
    "\n",
    "\n",
    "\n",
    "fit_PEG<- workflow() |>\n",
    "          add_recipe(recipe_PEG) |>\n",
    "          add_model(knn_spec) |>\n",
    "          fit(data = new_training_data)\n",
    "\n",
    "test_predictions_PEG <- predict(fit_PEG, new_testing_data) |>\n",
    "  bind_cols(new_testing_data)\n",
    "\n",
    "\n",
    "classification_metrics_PEG <- test_predictions_PEG |>\n",
    "metrics(truth = UNS, estimate=.pred_class)|>\n",
    "filter(.metric == \"accuracy\")\n",
    "\n",
    "\n",
    "classification_metrics_PEG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bad21-04cb-47f7-b1f1-5784ca92a0c3",
   "metadata": {},
   "source": [
    "><b> Figure 11: </b>\n",
    ">\n",
    ">Accuracy metric with PEG as the only predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086d2c6-cd6e-4a27-b311-513d421a23be",
   "metadata": {},
   "source": [
    "As we removed the predictor LPR, the accuracy of the model dropped, indicating that LPR still plays an important role in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c1569c-4b51-42af-ad48-119d36f04297",
   "metadata": {},
   "source": [
    "### Summary of Methods\n",
    "In the analysis section, we begin by summarizing key characteristics of the dataset, focusing on mean exam perforamce, study time, and observations with missing values. Using ggpair and ggplot, we identify LPR and PEG as crucial predictors, with UNS as the target class for our knn classification.\n",
    "\n",
    "We proceed with cross-validation, tuning the classifier and perform an linear model to find an optimal k-value for our knn model. Both k = 3 and k = 4 has the same accuracy, and we chose k = 3 to prevent a tie for our 4 classifier. The final model, built with k = 3, achieves a 95% accuracy on the testing dataset. Moving forward, we summarize the distribution of false positives and false negatives, finding potential areas of improvement.\n",
    "\n",
    "A crucial aspect of our analysis involves understanding the individual contributions of PEG and LPR in our prediction model. With performing the model with a single predictor, we can conclude that PEG plays a dominant role in predictions, while LPR consistently supports the model's outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3264bd74-bcb2-4fb3-b96f-e455a9c817b7",
   "metadata": {},
   "source": [
    "## Discussions\n",
    "\n",
    "Using the k-nearest neighbors (KNN) model, we achieved an impressive 95% accuracy in predicting a user's knowledge level based on the exam performance predictors PEG (exam performance on the goal subject) and LPR (exam performance on related subjects). In our model, predictor PEG seems to be playing a crucial role in predicting knowledge levels, as we achieve 80% accuracy in predicting user knowledge levels when using it as the only predictor. LPR, on the other hand, plays a minor role in influencing predictions. It is surprising to note that there is no significant correlation between study time and exam performance, posing an unresolved question for our model. This observation aligns with Morrison's perspective (2016), suggesting that study outcomes may not always correlate with the time invested; rather, the effectiveness of study methods plays a more crucial role. Further investigation into the dynamics between study habits and academic outcomes will be needed to fully answer the question. \n",
    "\n",
    "\n",
    "Despite the uncertainty regarding the relationship between study time and exam performance, our model aligns with our initial hypothesis: individuals with higher exam performance tend to have a higher knowledge level. \n",
    "\n",
    "\n",
    "The goal of this model is to help students and educators better understand how to approach learning and assessments, and we hope that our research findings have the potential to reshape perspectives and drive educational changes, leading to potential improvements in learning and assessment methods. We believe that these outcomes can contribute to a positive impact on the educational landscape, fostering continuous improvement and adaptation to evolving needs and challenges.\n",
    "\n",
    "### Expected Outcomes and Significance\n",
    "\n",
    "The findings should not only allow us to predict a user's knowledge level based on the different variables, but also show whether spending a lot of time studying and performing well in exams is correlated to having a high knowledge level in a subject. The results of the findings could have several impacts: for example, a student's perspective on test-taking and studying may be shifted if the findings show that studying a lot and high performance in exams does not have a strong correlation with high knowledge level. Additionally, an educator may consider reforming their curriculum if a student's performance on tests is not indicative of them actually gaining a high level of knowledge for the material. Some future questions the findings could hypothetically lead to, depending on the outcomes of this project, are:\n",
    "\n",
    "- Are there methods of evaluating a student's learning that are better than exams, in terms of helping students gain high knowledge levels of subjects?\n",
    "- If study time does not necessarily correlate with having a high knowledge level, which study methods (i.e. repetition) could be used to help students retain a high knowledge level?\n",
    "- If a student has a high knowledge level of one subject, will it be easier for them to gain a high knowledge level of a related subject?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e4a005-cdcd-468b-a957-6b1e5c4b124e",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Kahraman,Hamdi, Colak,Ilhami, and Sagiroglu,Seref. (2013). User Knowledge Modeling. UCI Machine Learning Repository. https://doi.org/10.24432/C5231X.\n",
    "\n",
    "Morrison, N. (2016). The Secret of Effective Learning May Be Less Study, Not More. Forbes. https://www.forbes.com/sites/nickmorrison/2016/05/30/the-secret-of-effective-learning-may-be-less-study-not-more/?sh=759e31818c7e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03aca68-5486-4816-98b3-d183034d2411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
